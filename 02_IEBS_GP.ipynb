{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "727ea47b-3486-4fc2-9b81-365b0828c486",
   "metadata": {},
   "source": [
    "# IEBS\n",
    "### Proyecto Global - Fin de Postgrado\n",
    "--- \n",
    "- Aplicacion\n",
    "- Alumno: Gabriel Rey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e57416-18b0-4269-bcc9-bdf21458ae36",
   "metadata": {},
   "source": [
    "## Importamos librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c057fa69-729e-432f-8ac5-ea0e5a0e7b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython import display as ipd\n",
    "from PIL import Image\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bf56a30-72c6-49b0-9241-b885d68034c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1f497fd-f604-4230-bf9f-6b545a1de0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import img_to_array, load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a7ffd7-723c-46ea-ae72-fb0afd9103ab",
   "metadata": {},
   "source": [
    "### Cargar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6362272d-e4a3-4c75-a215-158e2881f4ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "model = tf.keras.models.load_model(cwd + '\\\\Modelos\\\\modelo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27e0b517-af02-4579-bd43-43868472f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "clases = ['BENTEVEO_COMÚN',\n",
    "          'CABECITANEGRA_COMÚN',\n",
    "          'CALANDRIA_GRANDE',\n",
    "          'CARDENAL_AMARILLO',\n",
    "          'CARDENAL_COMUN',\n",
    "          'COTORRA',\n",
    "          'GOLONDRINA_DOMÉSTICA',\n",
    "          'GORRIÓN', 'HORNERO',\n",
    "          'JILGUERO_DORADO',\n",
    "          'RUIDO',\n",
    "          'ZORZAL_COLORADO']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d19f601-12b7-4662-a694-0101f7d68fc8",
   "metadata": {},
   "source": [
    "## Obtener audio de mic para prediccion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff8fdaf-ac10-4b37-91d6-3b05201de8b5",
   "metadata": {},
   "source": [
    "#### Abrimos el canal de audio con los parámeteros de configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8ebf066-d268-4496-89de-42fe36355c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bucle(tiempo_en_segundos, inicial):\n",
    "    return tiempo_en_segundos > time.time()-inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebd0bd77-8b36-4d53-b294-6be7747718bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class coefs:\n",
    "        \n",
    "    sr = 44100               # librosa sample rate input\n",
    "    sec = 5                  # seconds   \n",
    "    sshape = (128, 128)       # height x width\n",
    "    fmin = 500               # spectrum min frequency\n",
    "    fmax = 12500             # spectrum max frequency\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "706f0633-716a-4975-bcef-861b0414a556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def escucha_predice(FORMAT = pyaudio.paInt16, CHANNELS = 1, RATE = 44100, CHUNK = 1024, SECONDS = 20, bucle = 15, umbral = 0.9, clases=clases ):     \n",
    "    '''\n",
    "    FORMAT: pyaudio.paInt16       # Formato de lectura INT 16 bits\n",
    "    CHANNELS = 1                  # 1 mono, 2 stereo\n",
    "    RATE = 44100                  # Frecuencia de muestreo típica para audio\n",
    "    CHUNK = 2048                  # Tamaño del paquete a procesar  (samples per data frame)\n",
    "    SECONDS = 5                   # Tiempo en segundos\n",
    "    '''\n",
    "\n",
    "    acum_pred = [] \n",
    "    acum_indx = [] \n",
    "    inicial=time.time()\n",
    "    while Bucle(bucle, inicial):\n",
    "    \n",
    "        # Instanciar PyAudio\n",
    "        py_audio = pyaudio.PyAudio()\n",
    "\n",
    "        # Instanciamos objeto de toma de audio\n",
    "        stream = py_audio.open( format = FORMAT, channels = CHANNELS, rate = RATE, input=True, frames_per_buffer= CHUNK )\n",
    "\n",
    "        # Inicializar arreglo para almacenar frames\n",
    "        frames = []\n",
    "        \n",
    "        # Iniciamos ESCUCHA\n",
    "        print(\"Escuchando...\")\n",
    "\n",
    "\n",
    "        # Almaceno data en chunks para el tiempo=duracion\n",
    "        for i in range(0, int(RATE/ CHUNK * SECONDS)):\n",
    "            data = stream.read(CHUNK)                         # Leemos paquetes de longitud CHUNK\n",
    "            frames.append(data)\n",
    "\n",
    "        # Detenemos servicios\n",
    "        stream.stop_stream()             \n",
    "        stream.close()\n",
    "        py_audio.terminate()\n",
    "        print(\"Stop.\")\n",
    "\n",
    "        \n",
    "    #------------------------------------------------------------------------------------------------------------------   \n",
    "\n",
    "        # Grabar audio a disco\n",
    "        sound_file = wave.open(\"audio_captur.wav\", 'wb')\n",
    "        sound_file.setnchannels(1)\n",
    "        sound_file.setsampwidth(py_audio.get_sample_size(pyaudio.paInt16))\n",
    "        sound_file.setframerate(44100)\n",
    "        sound_file.writeframes(b''.join(frames))\n",
    "        sound_file.close()\n",
    "\n",
    "    #-----------------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # Cargar audio grabado\n",
    "        audio, _ = librosa.load(\"audio_captur.wav\", sr=None)\n",
    "        \n",
    "        for n in range(5):\n",
    "            start = np.random.randint(1, len(audio)-(coefs.sec * coefs.sr))\n",
    "            chunk = audio[start:start + coefs.sec * coefs.sr]\n",
    "\n",
    "            # Espectrograma para cada segmento de audio -------------------------\n",
    "            hop_length = int(coefs.sec * coefs.sr / (coefs.sshape[1] - 1))\n",
    "            mel_spec = librosa.feature.melspectrogram(y = chunk, \n",
    "                                                      sr = coefs.sr, \n",
    "                                                      n_fft = 1024, \n",
    "                                                      hop_length = hop_length, \n",
    "                                                      n_mels = coefs.sshape[0], \n",
    "                                                      fmin = coefs.fmin, \n",
    "                                                      fmax = coefs.fmax)\n",
    "\n",
    "            mel_spec = librosa.power_to_db(mel_spec**2, ref=np.max) \n",
    "\n",
    "            # Normalize\n",
    "            mel_spec -= mel_spec.min()\n",
    "            mel_spec /= mel_spec.max()\n",
    "\n",
    "            # Grabar imagen ------------------------------------------------------\n",
    "            im = Image.fromarray(mel_spec * 255.0).convert(\"L\")\n",
    "            im.save(f'img{n}.png')\n",
    "\n",
    "            imagenMod = load_img(f'img{n}.png', target_size=(128,128))\n",
    "            imagenMod = img_to_array(imagenMod)\n",
    "            imagenMod = np.expand_dims(imagenMod, axis=0) #(alto, ancho, 3) -> (1, alto, ancho, 3) \n",
    "\n",
    "            # Prediccion\n",
    "            pred = model.predict(imagenMod).astype(\"float32\")\n",
    "        \n",
    "            # Acumular indices\n",
    "            acum_indx.append(np.argmax(pred))\n",
    "            \n",
    "            # Acumular predicciones\n",
    "            acum_pred.append(pred[0][np.argmax(pred)])\n",
    "            \n",
    "            # Procesar predicciones y presentar\n",
    "            unicos, cuenta = np.unique(acum_indx, return_counts=True)\n",
    "            \n",
    "\n",
    "        print(\"###################################\")\n",
    "        if len(acum_indx) > len(unicos) or len(unicos)==1:\n",
    "\n",
    "            prob = c = 0\n",
    "            for i in range(len(acum_indx)):\n",
    "                if acum_indx[i] == unicos[np.argmax(cuenta)]:\n",
    "                    prob += acum_pred[i]\n",
    "                    c = c+1\n",
    "            prob /= c\n",
    "            if prob >= umbral:\n",
    "                print(clases[unicos[np.argmax(cuenta)]], end=\"\")\n",
    "                print(f\"  Probabilidad: {round(prob,4)}\")\n",
    "            else:\n",
    "                print(f\"No se puede predecir con umbral >= {umbral}\")\n",
    "        else:\n",
    "            print(\"No se puede predecir\")\n",
    "\n",
    "        print(acum_indx)\n",
    "        print(\"###################################\")\n",
    "        print()\n",
    "\n",
    "    \n",
    "    return [acum_pred, acum_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05cb99f9-77b6-4e1e-8b43-6dfaf47110df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escuchando...\n",
      "Stop.\n",
      "###################################\n",
      "RUIDO  Probabilidad: 0.9475\n",
      "[10, 10, 4, 10, 10]\n",
      "###################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acum_pred, acum_indx = escucha_predice(bucle = 20, umbral = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfdc893-9e58-470f-90b4-4a8edfe89b1f",
   "metadata": {},
   "source": [
    "Recomendaciones para las pruebas de audio:\n",
    "- Utilizar un smartphone para ejecutar los audios, no este mismo computador.\n",
    "- Utilizar un ambiente silencioso, ya que no está depurado el control de ruidos\n",
    "\n",
    "Algunos links de prueba (fuente YouTube):\n",
    "\n",
    "- Benteveo común\n",
    "    - https://www.youtube.com/watch?v=bRPgMuPJeY4&t=258s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fccb37-90e0-4cbb-9edb-aed3216a1269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
